{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Analysis\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this project, we will experiment and evaluate different methods of optimising a set of analysis cuts. This is used to simplify the dataset in order to then determine if an experiment's outcome is significant enough to call a new discovery. \n",
    "\n",
    "We will determine the optimal cut, maximising the significance of the signal events using the following formula: \n",
    "\n",
    "\\begin{equation}\n",
    "s = \\frac{N_s}{\\sqrt{N_b}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal 1\n",
    "\n",
    "Firstly, we will create a class for generating the signal and background toy distributions. \n",
    "\n",
    "Using the Monte Carlo rejection sampling method, we generated the events we will then perform the cuts on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distribution: \n",
    "    '''\n",
    "        A class to create the distributions for the background and signal using the Monte Carlo method.\n",
    "\n",
    "        Attributes: \n",
    "        -----------\n",
    "            mean_s : int\n",
    "                mean of the signal distribution\n",
    "            width_s : int\n",
    "                width of the signal distribution\n",
    "            mean_b : int\n",
    "                mean of the background distribution\n",
    "            width_b : int\n",
    "                width of the background distribution\n",
    "            events_s : int\n",
    "                number of signal events\n",
    "            events_b : int\n",
    "                number of background events\n",
    "\n",
    "        Methods: \n",
    "        --------\n",
    "        gaussian():\n",
    "            this creates the distribution using the Monte Carlo method of rejection sampling\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, mean_s, width_s, mean_b, width_b, events_s, events_b):\n",
    "        '''\n",
    "        Construct all the necessary attributes for the Distribution object.\n",
    "\n",
    "        Parameters: \n",
    "        -----------\n",
    "            mean_s : int\n",
    "                mean of the signal distribution\n",
    "            width_s : int\n",
    "                width of the signal distribution\n",
    "            mean_b : int\n",
    "                mean of the background distribution\n",
    "            width_b : int\n",
    "                width of the background distribution\n",
    "            events_s : int\n",
    "                number of signal events\n",
    "            events_b : int\n",
    "                number of background events\n",
    "\n",
    "        '''\n",
    "        self.mean_s = mean_s\n",
    "        self.width_s = width_s\n",
    "        self.mean_b = mean_b\n",
    "        self.width_b = width_b\n",
    "        self.events_s = events_s\n",
    "        self.events_b = events_b\n",
    "        \n",
    "\n",
    "    def gaussian(self):\n",
    "        '''\n",
    "        This is where we will create the gaussian distributions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        x_s : NpArray\n",
    "            array of x coordinates of signal events\n",
    "        x_b : NpArray\n",
    "            array of x coordinates of background events\n",
    "        '''\n",
    "\n",
    "        x_s = np.array([])\n",
    "        x_b = np.array([])\n",
    "\n",
    "        # for 'random sampling' we first created a large number of random numbers to find the maximum value of the distribution function\n",
    "        a_s = np.random.uniform(-3*self.width_s + self.mean_s, 3*self.width_s + self.mean_s, 1000)\n",
    "        sigma_s = self.width_s/2\n",
    "        p_a_s = 1/(sigma_s*np.sqrt(2*np.pi))*np.exp(-1/2*((a_s-self.mean_s)/sigma_s)**2)\n",
    "        p_max_s = np.max(p_a_s)\n",
    "\n",
    "        a_b = np.random.uniform(-3*self.width_b + self.mean_b, 3*self.width_b + self.mean_b, 1000)\n",
    "        sigma_b = self.width_b/2\n",
    "        p_a_b = 1/(sigma_b*np.sqrt(2*np.pi))*np.exp(-1/2*((a_b-self.mean_b)/sigma_b)**2)\n",
    "        p_max_b = np.max(p_a_b)\n",
    "\n",
    "        # here, we implement rejection sampling for creating the gaussian distributions\n",
    "        while len(x_s) < self.events_s:\n",
    "            x_trial_s = np.random.uniform(-3*self.width_s + self.mean_s, 3*self.width_s + self.mean_s)\n",
    "            p_x_s = 1/(sigma_s*np.sqrt(2*np.pi))*np.exp(-1/2*((x_trial_s-self.mean_s)/sigma_s)**2)\n",
    "            c_s = np.random.uniform(0, p_max_s)\n",
    "            if p_x_s > c_s:\n",
    "                x_s = np.append(x_s, x_trial_s) \n",
    "\n",
    "        while len(x_b) < self.events_b:\n",
    "            x_trial_b = np.random.uniform(-3*self.width_b + self.mean_b, 3*self.width_b + self.mean_b)\n",
    "            p_x_b = 1/(sigma_b*np.sqrt(2*np.pi))*np.exp(-1/2*((x_trial_b-self.mean_b)/sigma_b)**2)\n",
    "            c_b = np.random.uniform(0, p_max_b)\n",
    "            if p_x_b > c_b:\n",
    "                x_b = np.append(x_b, x_trial_b) \n",
    "\n",
    "        # ordering the NpArrays\n",
    "        x_s = np.sort(x_s)\n",
    "        x_b = np.sort(x_b)\n",
    "\n",
    "        return x_s, x_b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will illustrate the correct implementation of the Monte Carlo method by plotting the histograms of the generated signal and background distributions, alongside the corresponding analytical gaussian distributions generated by Python's in-built functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s, x_b = Distribution(15, 2, 10, 5, 1000, 2000).gaussian()\n",
    "bins = np.linspace(0, 25, 50)\n",
    "\n",
    "plt.hist(x_s, bins = bins, histtype = 'step')\n",
    "plt.hist(x_b, bins = bins, histtype = 'step')\n",
    "\n",
    "# analytic signal distribution\n",
    "x_axis_s = np.arange(0, 25, 0.01)\n",
    "plt.plot(x_axis_s, norm.pdf(x_axis_s, 15,2 )*1000)\n",
    "\n",
    "# analytic background sitribution\n",
    "x_axis_b = np.arange(0, 25, 0.01)\n",
    "plt.plot(x_axis_b, norm.pdf(x_axis_b, 10, 5)*2000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal 2\n",
    "\n",
    "Here we will implement the bisection method to maximise the significance in order to determine the optimal cut. \n",
    "\n",
    "Firstly, however, we will calcualte the significance values for every possible cut value and plot the graph.\n",
    "\n",
    "The optimal cut value result outputted from this function will then be used for testing the validity of the bisection and the Nelder Mead method, both of which will be applied to the list of significance vales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance(x_s, x_b):\n",
    "    '''\n",
    "    In this function we  plot the significance values against the x values and determine the optimal cut.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        x_s : NpArray\n",
    "            array contatining the x values for the signal events.\n",
    "        x_b : NpArray\n",
    "            array contatining the x values for the background events.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        sign : list\n",
    "            list of the signinificance values\n",
    "        # cut_value : int\n",
    "            the x value of the maximum significance\n",
    "        x_axis : list \n",
    "            list of values of the x axis \n",
    "\n",
    "    '''\n",
    "\n",
    "    x = np.sort(np.concatenate((x_s, x_b)))\n",
    "    x_copy = x\n",
    "    sign = []\n",
    "    x_axis = []\n",
    "\n",
    "    while x[0] != x_s[-1]:\n",
    "        s = len([i for i in x_s if i >= x[0]])/np.sqrt(len([j for j in x_b if j >= x[0]]))\n",
    "        x_axis.append(x[0])\n",
    "        x = x[1: ]\n",
    "        sign.append(s)\n",
    "\n",
    "    # index for value of the maximum significance\n",
    "    index = np.where(sign == np.max(sign))[0][0]\n",
    "    cut_value = x_copy[index]\n",
    "\n",
    "    return sign, cut_value, x_axis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the significance values against all possible cut values (list of combined positions of signal and backgound events)\n",
    "x_s, x_b = Distribution(15, 2, 10, 5, 1000, 2000).gaussian()\n",
    "sign, cut_value, x_axis = significance(x_s, x_b)\n",
    "\n",
    "plt.plot(x_axis, sign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we implement the bisection method, finding the ideal cut by maximising the significance.\n",
    "\n",
    "We chose two boundaries, a and b, expecting the maximum significance to be between them. Then, we calculate the midpoint,of these two, m, and two futher midpoints, l and r, between the initial boundaries and their centre m. We evaluate the value of the significance at each of the five points and then redefine them accordingly. Repeat this process until either a number of iterations has been reached, or the boundaries, a and b, have a small enough gap between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection(x_axis, f, lower, upper, gap, iterations):\n",
    "    '''\n",
    "    Function implementing the bisection method, in order to find the cut value for maximum significance. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        x_axis : list\n",
    "            list of all the x values.\n",
    "        f : list \n",
    "            the list of values of function we wish to maximise - in our case this will be the significance.\n",
    "        lower : int\n",
    "            lower initally imposed bound\n",
    "        upper : int\n",
    "            upper initially imposed bound\n",
    "        gap : int\n",
    "            minimum distance between the found boundaries for bisection method to terminate.\n",
    "        iterations : int\n",
    "            number of iterations \n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "        cut_value : int\n",
    "            the location on the x axis where the maximum significance was found\n",
    "\n",
    "    '''\n",
    "    \n",
    "    a = [i for i,v in enumerate(x_axis) if v > lower][0]\n",
    "    b = [i for i,v in enumerate(x_axis) if v > upper][0]\n",
    "\n",
    "    for _ in range(iterations):\n",
    "\n",
    "        m = int(a + (b - a)/2)\n",
    "        l = int(a + (m - a)/2)\n",
    "        r = int(m + (b - m)/2)\n",
    "\n",
    "        # indexes 0, 1, 2, 3, 4\n",
    "        for i in [a, l, m, r, b]:\n",
    "            values = f[i]\n",
    "\n",
    "        if f[0] == np.max(f) or f[1] == np.max(f):\n",
    "            b = m\n",
    "        \n",
    "        elif f[3] == np.max(f) or f[4] == np.max(f):\n",
    "            a = m\n",
    "\n",
    "        else:\n",
    "            a = l\n",
    "            b = r\n",
    "        \n",
    "        if (b - a) < gap:\n",
    "            break\n",
    "\n",
    "    cut_value = x_axis[a]\n",
    "\n",
    "    return cut_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will compare the cut value obtained from calculating the significances and finding the maximum value, versus applying the bisection method on the significance curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: in this Jupyter Notebook, I believe there is a problem with not being able to call the NpArrays from the significance() function, unless it was the previous one to be run. Therefore, I have repeated the function (and collapsed it s description for it to not bother much) in multiple cells that were meant for illustrating the validity of the methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance(x_s, x_b):\n",
    "    x = np.sort(np.concatenate((x_s, x_b)))\n",
    "    x_copy = x\n",
    "    sign = []\n",
    "    x_axis = []\n",
    "\n",
    "    while x[0] != x_s[-1]:\n",
    "        s = len([i for i in x_s if i >= x[0]])/np.sqrt(len([j for j in x_b if j >= x[0]]))\n",
    "        x_axis.append(x[0])\n",
    "        x = x[1: ]\n",
    "        sign.append(s)\n",
    "\n",
    "    # index for value of the maximum significance\n",
    "    index = np.where(sign == np.max(sign))[0][0]\n",
    "    cut_value = x_copy[index]\n",
    "\n",
    "    return sign, cut_value, x_axis\n",
    "x_s, x_b = Distribution(15, 2, 10, 5, 1000, 2000).gaussian()\n",
    "sign, cut_value, x_axis = significance(x_s, x_b)\n",
    "print('cut value from finding the maximum from the significances list: ',cut_value)\n",
    "\n",
    "cut_value_bisection = bisection(x_axis, sign, 13, 15, 0.01, 25)\n",
    "print('cut value found via the bisection method: ', cut_value_bisection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal 3\n",
    "\n",
    "We generate 1000 toy experiments, with the number of signal and background events varying according to a poisson distribion. We will apply the cut value found via calculating all significance values and finding the maximum value, and calculate the significance for each of the toy experiements, and a histogram of these significances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_experiment(cut_value, mean_s, width_s, mean_b, width_b, events_s, events_b, n):\n",
    "    '''\n",
    "    We vary the number of signal and backgound events obaying a poisson distribution and repeat the experiment n times, applying a cut value and calculating the significance each time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        cut_value : int\n",
    "            the optimal cut value found maximising the significance\n",
    "        mean_s : int\n",
    "            mean of the signal distribution\n",
    "        width_s : int\n",
    "            width of the signal distribution\n",
    "        mean_b : int\n",
    "            mean of the background distribution\n",
    "        width_b : int\n",
    "            width of the background distribution\n",
    "        events_s : int\n",
    "            number of signal events\n",
    "        events_b : int\n",
    "            number of background events\n",
    "        n : int\n",
    "            number of times the experiment is repeated\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        significance : NpArray\n",
    "            stores the significances of each experiment using the given cut value\n",
    "\n",
    "    '''\n",
    "\n",
    "    # generating the poisson distributed number of signal and background events \n",
    "    nr_background = np.random.poisson(lam = events_b, size = n)\n",
    "    nr_signal = np.random.poisson(lam = events_s, size = n)\n",
    "\n",
    "    significance = np.array([])\n",
    "\n",
    "    # calculating and storing the significance for each experiment\n",
    "    for i, j in zip(nr_signal, nr_background):\n",
    "        x_s, x_b = Distribution(mean_s, width_s, mean_b, width_b, i, j).gaussian()\n",
    "        s = len([i for i in x_s if i >= cut_value])/np.sqrt(len([j for j in x_b if j >= cut_value]))\n",
    "        significance = np.append(significance, s)\n",
    "        \n",
    "\n",
    "    return significance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance(x_s, x_b):\n",
    "    x = np.sort(np.concatenate((x_s, x_b)))\n",
    "    x_copy = x\n",
    "    sign = []\n",
    "    x_axis = []\n",
    "\n",
    "    while x[0] != x_s[-1]:\n",
    "        s = len([i for i in x_s if i >= x[0]])/np.sqrt(len([j for j in x_b if j >= x[0]]))\n",
    "        x_axis.append(x[0])\n",
    "        x = x[1: ]\n",
    "        sign.append(s)\n",
    "\n",
    "    # index for value of the maximum significance\n",
    "    index = np.where(sign == np.max(sign))[0][0]\n",
    "    cut_value = x_copy[index]\n",
    "\n",
    "    return sign, cut_value, x_axis\n",
    "# Plotting the histogram of the significance values applying a fixed cut value. (will take around 1m 42s)\n",
    "x_s, x_b = Distribution(15, 2, 10, 5, 1000, 2000).gaussian()\n",
    "sign, cut_value , x_axis = significance(x_s, x_b)\n",
    "\n",
    "cut_value = bisection(x_axis, sign, 13, 15, 0.001, 25)\n",
    "significance = repeat_experiment(cut_value, 15, 2, 10, 5, 1000, 2000, 1000)\n",
    "\n",
    "plt.hist(significance, bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal 4 Nelson Mead Method\n",
    "\n",
    "In this section, we will implement the Nelder Mead method in one dimension. This method is used to find the minimum or maximum of a given function. In our case, I have chosed to flip the significance curve by just applying a negative sign to every value in the list, in order work with minimising the function, rather than maximising it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, I created a helper function which helps find the closeset existing x value to one that we are looking for. As signal and background events are created randomly, there is no certainty that a value (for example a midpoint) that we are looking for, has a corresponding event at that location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_for_x(x, x_axis, sign):\n",
    "    '''\n",
    "    This function helps us find the nearest x value (and hence significance) to the searched value. \n",
    "\n",
    "    Parameters \n",
    "    ----------\n",
    "        x : int\n",
    "            value we are looking for\n",
    "        x_axis : list\n",
    "            list of x values generated\n",
    "        sign : list \n",
    "            list of the corresponding significance values\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        value_sign : int\n",
    "            significance value that corresponds to the closest generated x value to the one we were looking for\n",
    "\n",
    "    '''\n",
    "    \n",
    "    if x_axis[-1] < x:\n",
    "        a = -1\n",
    "    else:\n",
    "        a = [i for i,v in enumerate(x_axis) if v >= x][0]\n",
    "\n",
    "    value_sign = -sign[a]\n",
    "\n",
    "    return value_sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will implement the Nelder Mead method. \n",
    "\n",
    "Firstly, order the values of the function (significances) and pick the best, worst and second worst values and the corresponding coordinates. Find the centroid of the coordinates and the reflected point and evaluate the significances for each of them. Using this to guide us, we will redefine the points and, where needed, also calculate the extension points and the contracted points, evaluating the significances and redefining them, discarding the rest of the x coordinates.\n",
    "\n",
    "Repeat this process until the minimum significance is found and return the corresponding x coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nelson_mead_1d(x_axis, f):\n",
    "    '''\n",
    "    This function is applying the Nelder Mead method to minimise a one dimensional function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        x_axis : NpArray\n",
    "            contains all coordinates of the signal and background events\n",
    "        f : NpArray\n",
    "            the coresponding values of the function (in our case significances) for the given x coordinate values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        minimum : int\n",
    "            the coordinate on the x axis where the minimum is found\n",
    "\n",
    "    '''\n",
    "\n",
    "    # inverting the curve to apply minimization\n",
    "    f = [-i for i in f]\n",
    "    list = np.column_stack((x_axis, f))\n",
    "    sort = sorted(list, key = lambda l:l[1])\n",
    "    s = [l.tolist() for l in sort]\n",
    "    new_x_list = [row[0] for row in s]\n",
    "    \n",
    "    # choosing the best, second to worst and worst points\n",
    "    x1 = new_x_list[0]\n",
    "    xn1 = new_x_list[-1]\n",
    "    xn = new_x_list[-2]\n",
    "\n",
    "    for _ in range(5):\n",
    "\n",
    "        # centroid\n",
    "        x_0 = (sum(new_x_list) - xn1)/(len(new_x_list) - 1)\n",
    "\n",
    "        # reflection\n",
    "        x_r = x_0 + 1 * (x_0 - xn1)\n",
    "\n",
    "        if sig_for_x(x1, x_axis, f) <= sig_for_x(x_r, x_axis, f) and sig_for_x(x_r, x_axis, f) < sig_for_x(xn, x_axis, f):\n",
    "            xn1 = x_r\n",
    "\n",
    "        elif sig_for_x(x_r, x_axis, f) < sig_for_x(x1, x_axis, f):\n",
    "            # expanded point\n",
    "            x_e = x_0 + 2 * (x_r - x_0)\n",
    "\n",
    "            if sig_for_x(x_e, x_axis, f) < sig_for_x(x_r, x_axis, f):\n",
    "                xn1 = x_e\n",
    "\n",
    "            else: \n",
    "                xn1 = x_r\n",
    "\n",
    "        else: \n",
    "            if sig_for_x(x_r, x_axis, f) < sig_for_x(xn1, x_axis, f):\n",
    "                # contracted point on the outside\n",
    "                x_c = x_0 + 0.5 * (x_r - x_0)\n",
    "\n",
    "                if sig_for_x(x_c, x_axis, f) < sig_for_x(x_r, x_axis, f):\n",
    "                    xn1 = x_c\n",
    "\n",
    "                else: \n",
    "                    # shrink\n",
    "                    new_x_list = [(x1 + 0.5 * (i - x1)) for i in new_x_list[1:]]\n",
    "                    new_x_list.insert(0, x1)\n",
    "\n",
    "            elif sig_for_x(x_r, x_axis, f) >= sig_for_x(xn1, x_axis, f):\n",
    "                # contracted point on the inside\n",
    "                x_c = x_0 + 0.5 * (xn1 - x_0)\n",
    "\n",
    "                if sig_for_x(x_c, x_axis, f) < sig_for_x(xn1, x_axis, f):\n",
    "                    xn1 = x_c\n",
    "                \n",
    "                else:\n",
    "                    # shrink\n",
    "                    new_x_list = [(x1 + 0.5 * (i - x1)) for i in new_x_list[1:]]\n",
    "                    new_x_list.insert(0, x1)\n",
    "\n",
    "        if np.sort(new_x_list)[-1] < xn1:\n",
    "            a = np.sort(new_x_list)[-1]\n",
    "\n",
    "        else:\n",
    "            a = [v for i,v in enumerate(np.sort(new_x_list)) if v >= xn1][0]\n",
    "\n",
    "        new_x_list = new_x_list[:new_x_list.index(a)]\n",
    "        new_x_list.insert(-1, a)\n",
    "        \n",
    "\n",
    "        if len(new_x_list) == 1:\n",
    "            break\n",
    "\n",
    "        \n",
    "    minimum = new_x_list[0]\n",
    "\n",
    "    return minimum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance(x_s, x_b):\n",
    "    x = np.sort(np.concatenate((x_s, x_b)))\n",
    "    x_copy = x\n",
    "    sign = []\n",
    "    x_axis = []\n",
    "\n",
    "    while x[0] != x_s[-1]:\n",
    "        s = len([i for i in x_s if i >= x[0]])/np.sqrt(len([j for j in x_b if j >= x[0]]))\n",
    "        x_axis.append(x[0])\n",
    "        x = x[1: ]\n",
    "        sign.append(s)\n",
    "\n",
    "    # index for value of the maximum significance\n",
    "    index = np.where(sign == np.max(sign))[0][0]\n",
    "    cut_value = x_copy[index]\n",
    "\n",
    "    return sign, cut_value, x_axis\n",
    "# proving the efficiency of the method, here we are printing the cut value found via maximum significance from the list versus the Nelder Mead method, and they are identical.\n",
    "x_s, x_b = Distribution(15, 2, 11, 6, 1000, 2000).gaussian()\n",
    "sign, cut_value, x_axis = significance(x_s, x_b)\n",
    "print('via the significance graph: ', cut_value)\n",
    "print('via the nelder mead: ', nelson_mead_1d(x_axis, sign))\n",
    "\n",
    "plt.plot(x_axis, sign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal 5 Lower and Upper Cut \n",
    "\n",
    "I found the cuts using histograms and calculating the significance for each bin and the sum-significance for every possible lower and upper cut combination. I stored these in a matrix of three columns [lower_cut, upper_cut, significance], and was then looking for the maximum significance and selecting that row as the answer for optimal cuts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_lower(mean_s, width_s, x_s, x_b):\n",
    "        '''\n",
    "        In this function, we will find the optimal upper and lower cut on the data, using histograms.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "                mean_s : int\n",
    "                        mean of the signal distribution\n",
    "                width_s : int\n",
    "                        width of the signal distribution\n",
    "                x_s : NpArray\n",
    "                        array containing the x coordinates of the signal events\n",
    "                x_b : NpArray\n",
    "                        array containing the x coordinates of the background events\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "                x_low : int\n",
    "                        the optimal low cut found\n",
    "                x_high : int \n",
    "                        the optimal high cut found\n",
    "\n",
    "        '''\n",
    "\n",
    "        nr_bins = 50\n",
    "        lower_bound, upper_bound = mean_s - 2.5 * width_s, mean_s + 2.5 * width_s\n",
    "        bins = np.linspace(lower_bound, upper_bound, nr_bins)\n",
    "\n",
    "        bac = plt.hist(x_b, bins, histtype = 'step')\n",
    "        si = plt.hist(x_s, bins, histtype = 'step')\n",
    "\n",
    "        s = [l.tolist() for l in si[0]]\n",
    "        b = [l.tolist() for l in bac[0]]\n",
    "\n",
    "        i_start = [i for i, v in enumerate(s) if v > 0][0]\n",
    "        s.reverse()\n",
    "        i_end = [i for i, v in enumerate(s) if v > 0][0]\n",
    "        s.reverse()\n",
    "\n",
    "        s = s[i_start:-i_end]\n",
    "        b = b[i_start:-i_end]\n",
    "\n",
    "        store = np.array([0, 0, 0])\n",
    "\n",
    "        for low in range(len(s)):\n",
    "                for h in range(len(s)-low):\n",
    "                        high = h + low + 1\n",
    "                        sign = np.sum(s[low:high])/np.sqrt(np.sum(b[low:high]))\n",
    "                        add = np.array([low, high, sign])    \n",
    "                        store = np.vstack((store, add))\n",
    "\n",
    "        m_s = np.amax(store, axis = -1)\n",
    "\n",
    "        index = np.where(m_s == np.max(m_s))[0][0]\n",
    "        optimal = store[index]\n",
    "\n",
    "        steps_width = (upper_bound - lower_bound)/ nr_bins\n",
    "\n",
    "        x_low = (steps_width*(optimal[0]*2 + i_start*2 + 1))/2 + (mean_s - 2.5 * width_s)\n",
    "        x_high = (steps_width*(optimal[1]*2 + i_start*2 + 1))/2 + (mean_s - 2.5 * width_s)\n",
    "\n",
    "\n",
    "        return x_low, x_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance(x_s, x_b):\n",
    "    x = np.sort(np.concatenate((x_s, x_b)))\n",
    "    x_copy = x\n",
    "    sign = []\n",
    "    x_axis = []\n",
    "\n",
    "    while x[0] != x_s[-1]:\n",
    "        s = len([i for i in x_s if i >= x[0]])/np.sqrt(len([j for j in x_b if j >= x[0]]))\n",
    "        x_axis.append(x[0])\n",
    "        x = x[1: ]\n",
    "        sign.append(s)\n",
    "\n",
    "    # index for value of the maximum significance\n",
    "    index = np.where(sign == np.max(sign))[0][0]\n",
    "    cut_value = x_copy[index]\n",
    "\n",
    "    return sign, cut_value, x_axis\n",
    "# plotting the histogram of signal and backgound events and the found optimal lower and upper cut.\n",
    "mean_s, width_s = 15, 2\n",
    "x_s, x_b = Distribution(15, 2, 12, 5, 1000, 2000).gaussian()\n",
    "upper_lower(15, 2, x_s, x_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating 1000 toy experiments, varying the number of signal ad background events corresponding a poisson distribution and plotting the histogram of siginificances, given a lower and upper cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_experiment_up_low(cut_low, cut_high, mean_s, width_s, mean_b, width_b, events_s, events_b, n):\n",
    "    '''\n",
    "    We vary the number of signal and backgound events obaying a poisson distribution and repeat the experiment n times, applying a cut value and calculating the significance each time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        cut_low : int\n",
    "            the optimal lower cut value found maximising the significance\n",
    "        cut_high : int\n",
    "            the optimal high cut value found maximising the significance\n",
    "        mean_s : int\n",
    "            mean of the signal distribution\n",
    "        width_s : int\n",
    "            width of the signal distribution\n",
    "        mean_b : int\n",
    "            mean of the background distribution\n",
    "        width_b : int\n",
    "            width of the background distribution\n",
    "        events_s : int\n",
    "            number of signal events\n",
    "        events_b : int\n",
    "            number of background events\n",
    "        n : int\n",
    "            number of times the experiment is repeated\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        significance : NpArray\n",
    "            stores the significances of each experiment using the given cut value\n",
    "\n",
    "    '''\n",
    "\n",
    "    # generating the poisson distributed number of signal and background events \n",
    "    nr_background = np.random.poisson(lam = events_b, size = n)\n",
    "    nr_signal = np.random.poisson(lam = events_s, size = n)\n",
    "\n",
    "    significance = np.array([])\n",
    "\n",
    "    # calculating and storing the significance for each experiment\n",
    "    for i, j in zip(nr_signal, nr_background):\n",
    "        x_s, x_b = Distribution(mean_s, width_s, mean_b, width_b, i, j).gaussian()\n",
    "        s = len([i for i in x_s if (i >= cut_low and i <= cut_high)])/np.sqrt(len([j for j in x_b if (j >= cut_low and j <= cut_high)]))\n",
    "        significance = np.append(significance, s)\n",
    "\n",
    "    return significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance(x_s, x_b):\n",
    "    x = np.sort(np.concatenate((x_s, x_b)))\n",
    "    x_copy = x\n",
    "    sign = []\n",
    "    x_axis = []\n",
    "\n",
    "    while x[0] != x_s[-1]:\n",
    "        s = len([i for i in x_s if i >= x[0]])/np.sqrt(len([j for j in x_b if j >= x[0]]))\n",
    "        x_axis.append(x[0])\n",
    "        x = x[1: ]\n",
    "        sign.append(s)\n",
    "\n",
    "    # index for value of the maximum significance\n",
    "    index = np.where(sign == np.max(sign))[0][0]\n",
    "    cut_value = x_copy[index]\n",
    "\n",
    "    return sign, cut_value, x_axis\n",
    "# I have adjusted the mean of the backgound distribution to 12 here, to make sure in each bin where there are signal events, \n",
    "# there will also be backgound events, so that the significance is not infinity.\n",
    "x_s, x_b = Distribution(15, 2, 12, 5, 1000, 2000).gaussian()\n",
    "sign, cut_value , x_axis = significance(x_s, x_b)\n",
    "\n",
    "low_cut, high_cut = upper_lower(15, 2, x_s, x_b)\n",
    "print(low_cut, high_cut)\n",
    "significance = repeat_experiment_up_low(low_cut, high_cut, 15, 2, 12, 5, 1000, 2000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the histogram of the significance values applying the fixed cut values. \n",
    "plt.hist(significance, bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we created a more complicated toy distribution with more dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2D distribution has a corresponding 4d graph of significances. for nelder mead - every coordinate will have a value. \\\n",
    "Have a function outside the Nelder mead, calculating the value at that point for lower, upper cut for x and y coordinates. \n",
    "\n",
    "Implement the Nelder Mead for multi dimensional graphs and find the optimal point coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the signal and backgound events in 2 dimensions\n",
    "sigx, sigy, rho = 5, 5, -0.4\n",
    "cov_mat = [[sigx**2, rho * sigx * sigy], [rho * sigx * sigy, sigy**2]]\n",
    "sX, sY = np.random.multivariate_normal([8, 10], cov_mat, size=1000).T\n",
    "\n",
    "b_sigx, b_sigy, b_rho = 10, 15, 0.1\n",
    "b_cov_mat = [[b_sigx**2, b_rho * b_sigx * b_sigy], [b_rho * b_sigx * b_sigy, b_sigy**2]]\n",
    "bX, bY = np.random.multivariate_normal([10, 15], b_cov_mat, size=10000).T\n",
    "\n",
    "plt.scatter(bX, bY)\n",
    "plt.scatter(sX, sY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a helper function, calculating the significance of a point - counting the number of events from a square of fixed size at some given coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point(p, sX, sY, bX, bY):\n",
    "    '''\n",
    "    Function to find the value of significance for given x, y lower, upper cuts. \n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "        p : NpArray\n",
    "            gives the coordinates of the point we want the significance from\n",
    "        sX : NpArray\n",
    "            array of the x coordinates of the signal events\n",
    "        sY : NpArray\n",
    "            array of the y coordinates of the signal events\n",
    "        bX : NpArray\n",
    "            array of the x coordinates of the background events\n",
    "        bY : NpArray\n",
    "            array of the y coordinates of the background events\n",
    "\n",
    "    Return\n",
    "    -------\n",
    "        significance : int\n",
    "            value of the significance (Ns/sqrt(Nb)) for given parameters counting the amount of signal and background events in a given box\n",
    "    \n",
    "    '''\n",
    "\n",
    "    nr_s = 0\n",
    "    nr_b = 0\n",
    "\n",
    "    size = 5\n",
    "\n",
    "    for i in range(len(sX)):\n",
    "        if (sX[i] > p[0] - size) & (sX[i] < p[0] + size) & (sY[i] > p[1] - size) & (sY[i] < p[1] + size) == 1:\n",
    "            nr_s = nr_s + 1\n",
    "\n",
    "        if (bX[i] > p[0] - size) & (bX[i] < p[0] + size) & (bY[i] > p[1] - size) & (bY[i] < p[1] + size) == 1:\n",
    "            nr_b = nr_b + 1\n",
    "\n",
    "    significance = -(nr_s / np.sqrt(nr_b))\n",
    "\n",
    "    return significance\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will implement the Nelder Mead method on a 2 dimensional space, which means that we will operate with a 3 dimensional simplex. Initially, we will start form 3 random points and odering them into the best, second worst and worst point, calculating their significances. Then, we will calculate their centroid and reflected point, evaluating the significances at every instance and when necessary also calculating the extended and contracted points. After each iteration and evaluation, the simplex points are updated. The process ends either after a certain number of iterations, or when the shortest side of the simplex is under a certain given value. The output of the Nelder Mead method is the point of maximum significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nelder_mead_2d(sX, sY, bX, bY, times, gap):\n",
    "    '''\n",
    "    Implementing the multi dimensional Nelder Mead simplex method on the generated scattered two dimensional signal and backgound events. \n",
    "\n",
    "    Parameters \n",
    "    ----------\n",
    "        sX : NpArray\n",
    "            array of the x coordinates of the signal events\n",
    "        sY : NpArray\n",
    "            array of the y coordinates of the signal events\n",
    "        bX : NpArray\n",
    "            array of the x coordinates of the background events\n",
    "        bY : NpArray\n",
    "            array of the y coordinates of the background events\n",
    "        times : int\n",
    "            number of times for the method to run before selecting the best point - termination condition\n",
    "        gap : int\n",
    "            size of the shortest distance between the points in the simplex - termination condition\n",
    "\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        p1 : NpArray\n",
    "            coordinates for the point where the significance is maximised\n",
    "        sign : int\n",
    "            maximum significance found\n",
    "\n",
    "    '''\n",
    "\n",
    "    # generating 3 random points for the starting Nelder Mead simplex\n",
    "    p1 = [sX[0], sY[0]]\n",
    "    pn = [sX[30], sY[5]]\n",
    "    pn1 = [sX[10], sY[30]]\n",
    "\n",
    "    for i in range(times):\n",
    "\n",
    "        p_list = [p1, pn, pn1]\n",
    "    \n",
    "        # ordering the significances \n",
    "        s = [point(p1, sX, sY, bX, bY), point(pn, sX, sY, bX, bY), point(pn1, sX, sY, bX, bY)]\n",
    "        s_ord = np.sort(s)\n",
    "        p1 = p_list[np.where(s == s_ord[0])[0][0]]\n",
    "        pn = p_list[np.where(s == s_ord[1])[0][0]]\n",
    "        pn1 = p_list[np.where(s == s_ord[-1])[0][0]]\n",
    "\n",
    "        # centroid point\n",
    "        p0 = [(p1[0] + pn[0])/2, (p1[1] + pn[1])/2]\n",
    "\n",
    "        # reflected point\n",
    "        pr = [p0[0] + 1 * (p0[0] - pn1[0]), p0[1] + 1 * (p0[1] - pn1[1])]\n",
    "        \n",
    "\n",
    "        if point(p1, sX, sY, bX, bY) <= point(pr, sX, sY, bX, bY) and point(pr, sX, sY, bX, bY) < point(pn, sX, sY, bX, bY):\n",
    "            pn1 = pr\n",
    "\n",
    "        elif point(pr, sX, sY, bX, bY) < point(p1, sX, sY, bX, bY):\n",
    "            # expanded point\n",
    "            pe = [p0[0] + 2 * (pr[0] - p0[0]), p0[1] + 2 * (pr[1] - p0[1])]\n",
    "\n",
    "            if point(pe, sX, sY, bX, bY) < point(pr, sX, sY, bX, bY):\n",
    "                pn1 = pe\n",
    "\n",
    "            else: \n",
    "                pn1 = pr\n",
    "        \n",
    "        else: \n",
    "            if point(pr, sX, sY, bX, bY) < point(pn1, sX, sY, bX, bY):\n",
    "                # contracted point on outside\n",
    "                pc = [p0[0] + 0.5 * (pr[0] - p0[0]), p0[1] + 0.5 * (pr[1] - p0[1])]\n",
    "\n",
    "                if point(pc, sX, sY, bX, bY) < point(pr, sX, sY, bX, bY):\n",
    "                    pn1 = pc\n",
    "\n",
    "                else: \n",
    "                    # shrink\n",
    "                    pn = [pn[0] + 0.5 * (pn[0] - p1[0]), pn[1] + 0.5 * (pn[1] - p1[1])]\n",
    "                    pn1 = [pn1[0] + 0.5 * (pn1[0] - p1[0]), pn1[1] + 0.5 * (pn1[1] - p1[1])]\n",
    "\n",
    "\n",
    "\n",
    "            elif point(pr, sX, sY, bX, bY) >= point(pn1, sX, sY, bX, bY):\n",
    "                # contracted point on the inside\n",
    "                pc = [p0[0] + 0.5 * (pn1[0] - p0[0]), p0[1] + 0.5 * (pn1[1] - p0[1])]\n",
    "\n",
    "                if point(pc, sX, sY, bX, bY) < point(pn1,  sX, sY, bX, bY):\n",
    "                    pn1 = pc\n",
    "                \n",
    "                else:\n",
    "                    # shrink\n",
    "                    pn = [pn[0] + 0.5 * (pn[0] - p1[0]), pn[1] + 0.5 * (pn[1] - p1[1])]\n",
    "                    pn1 = [pn1[0] + 0.5 * (pn1[0] - p1[0]), pn1[1] + 0.5 * (pn1[1] - p1[1])]\n",
    "\n",
    "\n",
    "            \n",
    "            # termination condition: checking if the shortest side of the simplex is smaller than the selected value of the gap\n",
    "            dist = [np.sqrt((pn1[0] - pn[0])**2 + (pn1[1] - pn[1])**2), np.sqrt((pn1[0] - p1[0])**2 + (pn1[1] - p1[1])**2), np.sqrt((p1[0] - pn[0])**2 + (p1[1] - pn[1])**2)]\n",
    "\n",
    "            if np.max(dist) < gap: \n",
    "                break\n",
    "\n",
    "    sign = -point(p1, sX, sY, bX, bY)\n",
    "            \n",
    "    return p1, sign\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sX, sY = np.random.multivariate_normal([1, 5], cov_mat, size=1000).T\n",
    "bX, bY = np.random.multivariate_normal([10, 15], b_cov_mat, size=10000).T\n",
    "\n",
    "p1, sign = nelder_mead_2d(sX, sY, bX, bY, 20, 1)\n",
    "print('the ideal point for the cut found has the coordinates: ', p1)\n",
    "print('the significance at this point is: ', sign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In conclusion, in order to find the optimal cut value on a dataset and maximise the significance various methods can be used, such as the bisection method or the Nelder Mead method, both of which have been explored in this project. To further optimise the data analysis, both low and high cut values can be found (Goal 5), and the Nelder Mead method can be applied for a more complicated model where more variables should be incorporated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d75cc7cbfa9ae50cbaa69331d8e370542d9164759623daca0f2a399f9e8aab6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
